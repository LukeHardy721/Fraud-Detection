{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f5e818",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195d140",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcae2f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 31)\n",
      "(56962, 31)\n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../data/processed_train_df.csv\")\n",
    "print(train_df.shape)\n",
    "\n",
    "test_df = pd.read_csv(\"../data/processed_test_df.csv\")\n",
    "print(test_df.shape)\n",
    "\n",
    "df = pd.concat([train_df, test_df])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55cc0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude labels\n",
    "\n",
    "y_train = train_df['Class']\n",
    "X_train = train_df.drop(columns=['Class'])\n",
    "\n",
    "y_test = test_df['Class']\n",
    "X_test = test_df.drop(columns=['Class'])\n",
    "\n",
    "labels = df['Class']\n",
    "df_unlabelled = df.drop(columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bd91603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build a validation with 20% of the data (25% of the train dataset)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acb62f",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "934bb3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.0015, n_estimators=300, n_jobs=-1,\n",
       "                random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>IsolationForest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.0015, n_estimators=300, n_jobs=-1,\n",
       "                random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.0015, n_estimators=300, n_jobs=-1,\n",
       "                random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    max_samples=\"auto\",\n",
    "    contamination=0.0015,  # expected proportion of anomalies; tune later - decided by quick online research\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89ce2c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.482424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.357364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anomaly_score  predicted_label  true_label\n",
       "0       0.401459                0           0\n",
       "1       0.482424                0           0\n",
       "2       0.533606                0           0\n",
       "3       0.357364                0           0\n",
       "4       0.444578                0           0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scores = iso.score_samples(X_test)\n",
    "\n",
    "anomaly_scores = -raw_scores\n",
    "\n",
    "pred_labels = (iso.predict(X_test) == -1).astype(int)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"anomaly_score\": anomaly_scores,\n",
    "    \"predicted_label\": pred_labels,\n",
    "    \"true_label\": y_test  # only for later evaluation\n",
    "}, index=X_test.index)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c460ce67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5598\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cutoff = np.quantile(anomaly_scores, 0.985)\n",
    "print(cutoff.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5809c8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9518\n",
      "PR AUC: 0.1577\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roc = roc_auc_score(y_test, anomaly_scores)\n",
    "pr_auc = average_precision_score(y_test, anomaly_scores)\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(confusion_matrix(y_test, pred_labels), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292574f",
   "metadata": {},
   "source": [
    "So, we can see that this model does not perform particularly well, especially when compared to the 0.76 PR AUC of our quick Logistic Regression model from EDA. Let's try tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436486fa",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d33a90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(y_true, scores, k=0.01):\n",
    "    \"\"\"\n",
    "    Compute Precision@k and Recall@k for anomaly scores.\n",
    "    y_true: array-like of shape (n,) with 0/1 labels\n",
    "    scores: array-like of shape (n,) with higher = more anomalous\n",
    "    k: fraction of samples to flag (e.g. 0.01 = top 1%)\n",
    "    \"\"\"\n",
    "    n = len(scores)\n",
    "    top_n = max(1, int(np.ceil(k * n)))  # at least one sample\n",
    "\n",
    "    # Get indices of top-k scores\n",
    "    idx = np.argsort(-scores)[:top_n]\n",
    "\n",
    "    # Precision = frauds / flagged\n",
    "    precision = y_true.iloc[idx].mean()\n",
    "\n",
    "    # Recall = frauds caught / total frauds\n",
    "    recall = y_true.iloc[idx].sum() / y_true.sum()\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c8e63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def tune_IF(param_grid, PRIMARY, SECONDARY, X_val=X_val, y_val=y_val):\n",
    "\n",
    "    runs = []\n",
    "    best_tuple = (-np.inf, -np.inf)  # (primary, secondary)\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_scores = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        iso = IsolationForest(max_features=1, random_state=42, n_jobs=-1, **params) # Used param_grid to work out max_features = 1 is optimal\n",
    "        iso.fit(X_train)\n",
    "\n",
    "        scores = -iso.score_samples(X_val)\n",
    "\n",
    "        roc = roc_auc_score(y_val, scores)\n",
    "        pr_auc = average_precision_score(y_val, scores)\n",
    "        p_at_1, r_at_1 = precision_recall_at_k(y_val, scores, k=0.01)\n",
    "        p_at_05, r_at_05 = precision_recall_at_k(y_val, scores, k=0.005)\n",
    "\n",
    "        runs.append({**params, \"ROC\": roc, \"pr_auc\": pr_auc, \"p_at_1\": p_at_1, \"r_at_1\": r_at_1, \"p_at_05\": p_at_05, \"r_at_05\": r_at_05})\n",
    "\n",
    "        primary_val = r_at_1 if PRIMARY == \"r_at_1\" else pr_auc\n",
    "        secondary_val = pr_auc if SECONDARY == \"pr_auc\" else r_at_1\n",
    "        cand_tuple = (primary_val, secondary_val)\n",
    "\n",
    "        if cand_tuple > best_tuple:\n",
    "            best_tuple = cand_tuple\n",
    "            best_params = params\n",
    "            best_model = iso\n",
    "            best_scores = scores\n",
    "\n",
    "    results_df = pd.DataFrame(runs).sort_values(\n",
    "        by=[PRIMARY, SECONDARY], ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"Top configs:\")\n",
    "    display(results_df.head(20))\n",
    "    print(\"\\nSelected params:\", best_params)\n",
    "    print(f\"Selected {PRIMARY}={best_tuple[0]:.4f}, {SECONDARY}={best_tuple[1]:.4f}\")\n",
    "\n",
    "    return(best_tuple, best_params, best_model, best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63973672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_05</th>\n",
       "      <th>r_at_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>500</td>\n",
       "      <td>0.948106</td>\n",
       "      <td>0.183098</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.164912</td>\n",
       "      <td>0.474747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>600</td>\n",
       "      <td>0.939069</td>\n",
       "      <td>0.181643</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>600</td>\n",
       "      <td>0.946261</td>\n",
       "      <td>0.179622</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>0.464646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>400</td>\n",
       "      <td>0.948435</td>\n",
       "      <td>0.176945</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>0.942789</td>\n",
       "      <td>0.176008</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>500</td>\n",
       "      <td>0.941321</td>\n",
       "      <td>0.175865</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>400</td>\n",
       "      <td>0.941630</td>\n",
       "      <td>0.175691</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>400</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.180897</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>600</td>\n",
       "      <td>0.938157</td>\n",
       "      <td>0.179011</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>500</td>\n",
       "      <td>0.938125</td>\n",
       "      <td>0.178556</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>400</td>\n",
       "      <td>0.936698</td>\n",
       "      <td>0.176808</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>0.943464</td>\n",
       "      <td>0.176330</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>600</td>\n",
       "      <td>0.942671</td>\n",
       "      <td>0.176283</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>500</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>0.173805</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>400</td>\n",
       "      <td>0.943557</td>\n",
       "      <td>0.173630</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>500</td>\n",
       "      <td>0.937825</td>\n",
       "      <td>0.182510</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>500</td>\n",
       "      <td>0.943589</td>\n",
       "      <td>0.176232</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>400</td>\n",
       "      <td>0.943658</td>\n",
       "      <td>0.174544</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap  max_samples  n_estimators       ROC    pr_auc    p_at_1  \\\n",
       "0        True         3072           500  0.948106  0.183098  0.107018   \n",
       "1        True         4096           600  0.939069  0.181643  0.107018   \n",
       "2        True         3072           600  0.946261  0.179622  0.107018   \n",
       "3        True         3072           400  0.948435  0.176945  0.107018   \n",
       "4        True         5120           600  0.942789  0.176008  0.107018   \n",
       "5        True         5120           500  0.941321  0.175865  0.107018   \n",
       "6        True         5120           400  0.941630  0.175691  0.107018   \n",
       "7        True         4096           400  0.938219  0.180897  0.105263   \n",
       "8       False         3072           600  0.938157  0.179011  0.105263   \n",
       "9       False         3072           500  0.938125  0.178556  0.105263   \n",
       "10      False         3072           400  0.936698  0.176808  0.105263   \n",
       "11      False         5120           600  0.943464  0.176330  0.105263   \n",
       "12      False         4096           600  0.942671  0.176283  0.105263   \n",
       "13      False         4096           500  0.942484  0.173805  0.105263   \n",
       "14      False         4096           400  0.943557  0.173630  0.105263   \n",
       "15       True         4096           500  0.937825  0.182510  0.103509   \n",
       "16      False         5120           500  0.943589  0.176232  0.103509   \n",
       "17      False         5120           400  0.943658  0.174544  0.101754   \n",
       "\n",
       "      r_at_1   p_at_05   r_at_05  \n",
       "0   0.616162  0.164912  0.474747  \n",
       "1   0.616162  0.154386  0.444444  \n",
       "2   0.616162  0.161404  0.464646  \n",
       "3   0.616162  0.157895  0.454545  \n",
       "4   0.616162  0.150877  0.434343  \n",
       "5   0.616162  0.150877  0.434343  \n",
       "6   0.616162  0.150877  0.434343  \n",
       "7   0.606061  0.150877  0.434343  \n",
       "8   0.606061  0.157895  0.454545  \n",
       "9   0.606061  0.154386  0.444444  \n",
       "10  0.606061  0.154386  0.444444  \n",
       "11  0.606061  0.157895  0.454545  \n",
       "12  0.606061  0.150877  0.434343  \n",
       "13  0.606061  0.147368  0.424242  \n",
       "14  0.606061  0.150877  0.434343  \n",
       "15  0.595960  0.150877  0.434343  \n",
       "16  0.595960  0.154386  0.444444  \n",
       "17  0.585859  0.154386  0.444444  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected params: {'bootstrap': True, 'max_samples': 3072, 'n_estimators': 500}\n",
      "Selected r_at_1=0.6162, pr_auc=0.1831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.6161616161616161, 0.18309834786122342),\n",
       " {'bootstrap': True, 'max_samples': 3072, 'n_estimators': 500},\n",
       " IsolationForest(bootstrap=True, max_features=1, max_samples=3072,\n",
       "                 n_estimators=500, n_jobs=-1, random_state=42),\n",
       " array([0.44412503, 0.4256351 , 0.4239817 , ..., 0.43053602, 0.43971931,\n",
       "        0.43540952]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRIMARY = \"r_at_1\"\n",
    "SECONDARY = \"pr_auc\"\n",
    "\n",
    "# Note that I have already narrowed down the param_grid through multiple iterations\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [400, 500, 600],\n",
    "    \"max_samples\": [3072, 4096, 5120],\n",
    "    \"bootstrap\": [False, True],\n",
    "    # Note: intentionally not tuning 'contamination' here\n",
    "}\n",
    "\n",
    "tune_IF(param_grid, PRIMARY, SECONDARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c92d3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c21af3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROC': 0.9573296257163529, 'pr_auc': 0.2354632595199347, 'p_at_1': 0.11754385964912281, 'r_at_1': 0.6836734693877551, 'p_at_05': 0.1824561403508772, 'r_at_05': 0.5306122448979592}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=500,\n",
    "    max_samples=3072,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso.fit(X_train)\n",
    "\n",
    "scores = -iso.score_samples(X_test)\n",
    "\n",
    "roc = roc_auc_score(y_test, scores)\n",
    "pr_auc = average_precision_score(y_test, scores)\n",
    "p_at_1, r_at_1 = precision_recall_at_k(y_test, scores, k=0.01)\n",
    "p_at_05, r_at_05 = precision_recall_at_k(y_test, scores, k=0.005)\n",
    "\n",
    "print({\"ROC\": roc, \"pr_auc\": pr_auc, \"p_at_1\": p_at_1, \"r_at_1\": r_at_1, \"p_at_05\": p_at_05, \"r_at_05\": r_at_05})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf2e16",
   "metadata": {},
   "source": [
    "Now let's try out these parameters on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008ef8d",
   "metadata": {},
   "source": [
    "## Evaluation on the Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7615e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROC': 0.9520840419613594, 'pr_auc': 0.24741896399788765, 'p_at_1': 0.11267111267111267, 'r_at_1': 0.6524390243902439, 'p_at_05': 0.17614035087719299, 'r_at_05': 0.5101626016260162}\n"
     ]
    }
   ],
   "source": [
    "scores = -iso.score_samples(df_unlabelled)\n",
    "\n",
    "roc = roc_auc_score(labels, scores)\n",
    "pr_auc = average_precision_score(labels, scores)\n",
    "p_at_1, r_at_1 = precision_recall_at_k(labels, scores, k=0.01)\n",
    "p_at_05, r_at_05 = precision_recall_at_k(labels, scores, k=0.005)\n",
    "\n",
    "print({\n",
    "    \"ROC\": roc,\n",
    "    \"pr_auc\": pr_auc,\n",
    "    \"p_at_1\": p_at_1,\n",
    "    \"r_at_1\": r_at_1,\n",
    "    \"p_at_05\": p_at_05,\n",
    "    \"r_at_05\": r_at_05\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebff4fc",
   "metadata": {},
   "source": [
    "Our tuned Isolation Forest achieved ROC AUC = 0.95 and PR AUC = 0.25.\n",
    "\n",
    "At a 1% review budget, this corresponds to 11% precision and 65% recall, a 65Ã— improvement over random guessing.\n",
    "In practice, this means fraud investigators could catch ~320 frauds (two-thirds of all fraud cases) while only reviewing 1% of total transactions.\n",
    "\n",
    "At a 0.5% review budget, this corresponds to 18% precision and 51% recall, a 102Ã— improvement over random guessing.\n",
    "In practice, this means fraud investigators could catch ~251 frauds (just over half of all fraud cases) while only reviewing 0.5% of total transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779468a",
   "metadata": {},
   "source": [
    "## Reducing Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881b2ea",
   "metadata": {},
   "source": [
    "In practice, it is feasible that increased PR AUC is not deemed to be worth the extra computational cost that comes with it, as only the top x% of transactions flagged as 'most suspicious' will be manually reviewed.  \n",
    "In this case, can we simplify the model so that it runs more efficiently, whilst maintaining good p_at_1 and r_at_1 scores?  \n",
    "Note that this assumes that the top 1% of transactions will be reviewed. Of course, if the percentage differs from 1% that would affect the necessary complexity of the model to retain performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "149a35f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_05</th>\n",
       "      <th>r_at_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.941423</td>\n",
       "      <td>0.180507</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.940168</td>\n",
       "      <td>0.178355</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.940989</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.942346</td>\n",
       "      <td>0.172965</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.171773</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>500</td>\n",
       "      <td>0.941034</td>\n",
       "      <td>0.169197</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.939615</td>\n",
       "      <td>0.178018</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>500</td>\n",
       "      <td>0.940880</td>\n",
       "      <td>0.168592</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>0.414141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>400</td>\n",
       "      <td>0.941185</td>\n",
       "      <td>0.164113</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>400</td>\n",
       "      <td>0.941321</td>\n",
       "      <td>0.163985</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>0.414141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>400</td>\n",
       "      <td>0.937330</td>\n",
       "      <td>0.162979</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>400</td>\n",
       "      <td>0.937258</td>\n",
       "      <td>0.162327</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>300</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.157175</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.404040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>500</td>\n",
       "      <td>0.938006</td>\n",
       "      <td>0.164760</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>500</td>\n",
       "      <td>0.937948</td>\n",
       "      <td>0.164044</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.150877</td>\n",
       "      <td>0.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>300</td>\n",
       "      <td>0.941066</td>\n",
       "      <td>0.156231</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>300</td>\n",
       "      <td>0.939585</td>\n",
       "      <td>0.159631</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>300</td>\n",
       "      <td>0.939420</td>\n",
       "      <td>0.158930</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap  max_samples  n_estimators       ROC    pr_auc    p_at_1  \\\n",
       "0       False         2048           500  0.941423  0.180507  0.107018   \n",
       "1       False         2048           400  0.940168  0.178355  0.107018   \n",
       "2        True         2048           500  0.940989  0.175679  0.103509   \n",
       "3        True         2048           300  0.942346  0.172965  0.103509   \n",
       "4        True         2048           400  0.940217  0.171773  0.103509   \n",
       "5       False         1024           500  0.941034  0.169197  0.103509   \n",
       "6       False         2048           300  0.939615  0.178018  0.101754   \n",
       "7        True         1024           500  0.940880  0.168592  0.101754   \n",
       "8       False         1024           400  0.941185  0.164113  0.101754   \n",
       "9        True         1024           400  0.941321  0.163985  0.101754   \n",
       "10       True          512           400  0.937330  0.162979  0.101754   \n",
       "11      False          512           400  0.937258  0.162327  0.101754   \n",
       "12      False         1024           300  0.940362  0.157175  0.101754   \n",
       "13       True          512           500  0.938006  0.164760  0.100000   \n",
       "14      False          512           500  0.937948  0.164044  0.100000   \n",
       "15       True         1024           300  0.941066  0.156231  0.100000   \n",
       "16       True          512           300  0.939585  0.159631  0.096491   \n",
       "17      False          512           300  0.939420  0.158930  0.096491   \n",
       "\n",
       "      r_at_1   p_at_05   r_at_05  \n",
       "0   0.616162  0.154386  0.444444  \n",
       "1   0.616162  0.154386  0.444444  \n",
       "2   0.595960  0.157895  0.454545  \n",
       "3   0.595960  0.150877  0.434343  \n",
       "4   0.595960  0.157895  0.454545  \n",
       "5   0.595960  0.150877  0.434343  \n",
       "6   0.585859  0.150877  0.434343  \n",
       "7   0.585859  0.143860  0.414141  \n",
       "8   0.585859  0.147368  0.424242  \n",
       "9   0.585859  0.143860  0.414141  \n",
       "10  0.585859  0.150877  0.434343  \n",
       "11  0.585859  0.150877  0.434343  \n",
       "12  0.585859  0.140351  0.404040  \n",
       "13  0.575758  0.150877  0.434343  \n",
       "14  0.575758  0.150877  0.434343  \n",
       "15  0.575758  0.136842  0.393939  \n",
       "16  0.555556  0.136842  0.393939  \n",
       "17  0.555556  0.136842  0.393939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected params: {'bootstrap': False, 'max_samples': 2048, 'n_estimators': 500}\n",
      "Selected r_at_1=0.6162, pr_auc=0.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.6161616161616161, 0.1805071983709993),\n",
       " {'bootstrap': False, 'max_samples': 2048, 'n_estimators': 500},\n",
       " IsolationForest(max_features=1, max_samples=2048, n_estimators=500, n_jobs=-1,\n",
       "                 random_state=42),\n",
       " array([0.45344264, 0.43138444, 0.43221518, ..., 0.4298399 , 0.44027876,\n",
       "        0.43344062]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRIMARY = \"r_at_1\"\n",
    "SECONDARY = \"pr_auc\"\n",
    "\n",
    "# Note that I have already narrowed down the param_grid through multiple iterations\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 400, 500],\n",
    "    \"max_samples\": [512, 1024, 2048],\n",
    "    \"bootstrap\": [False, True],\n",
    "    # Note: intentionally not tuning 'contamination' here\n",
    "}\n",
    "\n",
    "tune_IF(param_grid, PRIMARY, SECONDARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "608ccdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROC': 0.9578234642196777, 'pr_auc': 0.228558916354146, 'p_at_1': 0.11403508771929824, 'r_at_1': 0.6632653061224489, 'p_at_05': 0.16842105263157894, 'r_at_05': 0.4897959183673469}\n"
     ]
    }
   ],
   "source": [
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    max_samples=1024,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso.fit(X_train)\n",
    "\n",
    "scores = -iso.score_samples(X_test)\n",
    "\n",
    "roc = roc_auc_score(y_test, scores)\n",
    "pr_auc = average_precision_score(y_test, scores)\n",
    "p_at_1, r_at_1 = precision_recall_at_k(y_test, scores, k=0.01)\n",
    "p_at_05, r_at_05 = precision_recall_at_k(y_test, scores, k=0.005)\n",
    "\n",
    "print({\"ROC\": roc, \"pr_auc\": pr_auc, \"p_at_1\": p_at_1, \"r_at_1\": r_at_1, \"p_at_05\": p_at_05, \"r_at_05\": r_at_05})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2db4c",
   "metadata": {},
   "source": [
    "We can see that reducing the model complexity, we are still able to retain strong p_at_1 and r_at_1 values whilst reducing model complexity.\n",
    "\n",
    "From the above, we can reduce as far as n_estimators = 300, max_samples = 1024 before we start seeing meaningful drop offs in performance on the top 1% of suspicious transactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
