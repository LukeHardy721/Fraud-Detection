{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f5e818",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195d140",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcae2f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 31)\n",
      "(56962, 31)\n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../data/processed_train_df.csv\")\n",
    "print(train_df.shape)\n",
    "\n",
    "test_df = pd.read_csv(\"../data/processed_test_df.csv\")\n",
    "print(test_df.shape)\n",
    "\n",
    "df = pd.concat([train_df, test_df])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55cc0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude labels\n",
    "\n",
    "y_train = train_df['Class']\n",
    "X_train = train_df.drop(columns=['Class'])\n",
    "\n",
    "X_train.columns\n",
    "\n",
    "y_test = test_df['Class']\n",
    "X_test = test_df.drop(columns=['Class'])\n",
    "\n",
    "labels = df['Class']\n",
    "df_unlabelled = df.drop(columns=['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acb62f",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934bb3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.0015, n_estimators=300, n_jobs=-1,\n",
       "                random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>IsolationForest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.0015, n_estimators=300, n_jobs=-1,\n",
       "                random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.0015, n_estimators=300, n_jobs=-1,\n",
       "                random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    max_samples=\"auto\",\n",
    "    contamination=0.0015,  # expected proportion of anomalies; tune later - decided by quick online research\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ce2c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.363384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anomaly_score  predicted_label  true_label\n",
       "0       0.402470                0           0\n",
       "1       0.483837                0           0\n",
       "2       0.543463                0           0\n",
       "3       0.363384                0           0\n",
       "4       0.437474                0           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scores = iso.score_samples(X_test)\n",
    "\n",
    "anomaly_scores = -raw_scores\n",
    "\n",
    "pred_labels = (iso.predict(X_test) == -1).astype(int)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"anomaly_score\": anomaly_scores,\n",
    "    \"predicted_label\": pred_labels,\n",
    "    \"true_label\": y_test  # only for later evaluation\n",
    "}, index=X_test.index)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c460ce67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.561\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cutoff = np.quantile(anomaly_scores, 0.985)\n",
    "print(cutoff.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5809c8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9538\n",
      "PR AUC: 0.1522\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHHCAYAAACcHAM1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPP1JREFUeJzt3Qd8VGXWx/GTUJLQCRASpARFSpQaqgVkRVCKIKCgLiBFhQWkl7g0scCCLr3YKBYQUEHpIoisAtIEAYUFiYJSAkgXQsm8n/P4zuxMCJh452Zukt/3/cw7mXufuXNnWMyfc57nTpDL5XIJAACAgwUH+gQAAAD+DIEFAAA4HoEFAAA4HoEFAAA4HoEFAAA4HoEFAAA4HoEFAAA4HoEFAAA4HoEFAAA4HoEFsNG+ffukYcOGkj9/fgkKCpJFixb59fg//fSTOe6sWbP8etyM7L777jM3AJkLgQWZ3o8//ijPPvus3HrrrRIaGir58uWTu+++WyZMmCAXL1609bU7dOggO3fulJdfflneffddqV69umQWTz31lAlL+nmm9DlqWNP9env11VfTfPzDhw/LiBEjZPv27X46YwAZWfZAnwBgp6VLl8qjjz4qISEh0r59e7nzzjvl8uXL8tVXX8mAAQNk9+7d8sYbb9jy2vpLfMOGDfLPf/5TevToYctrlCpVyrxOjhw5JBCyZ88uv//+uyxevFgee+wxn33vv/++CYiXLl36S8fWwPLCCy9IdHS0VKlSJdXP++yzz/7S6wFwNgILMq34+Hhp27at+aW+Zs0aiYqK8uzr3r277N+/3wQauxw/ftzcFyhQwLbX0OqFhoJA0SCo1aq5c+deF1jmzJkjTZo0kY8++ihdzkWDU65cuSRnzpzp8noA0hctIWRaY8aMkfPnz8vbb7/tE1bcypQpI7169fI8vnr1qrz44oty2223mV/E+i/7559/XhITE32ep9ubNm1qqjQ1a9Y0gUHbTe+8845njLYyNCgpreRosNDnuVsp7p+96XN0nLdVq1bJPffcY0JPnjx5pFy5cuac/mwOiwa0e++9V3Lnzm2e27x5c/nhhx9SfD0NbnpOOk7n2nTs2NH88k+tJ554QpYvXy6nT5/2bNu8ebNpCem+5H777Tfp37+/VKxY0bwnbSk99NBDsmPHDs+YtWvXSo0aNczPej7u1pL7feocFa2Wbd26VerWrWuCivtzST6HRdty+meU/P03atRIChYsaCo5AJyPwIJMS9sUGiTuuuuuVI3v0qWLDBs2TKpVqybjxo2TevXqyahRo0yVJjn9Jd+6dWt54IEH5LXXXjO/+PSXvraYVMuWLc0x1OOPP27mr4wfPz5N56/H0mCkgWnkyJHmdR5++GH5+uuvb/q8zz//3PwyTkhIMKGkb9++sn79elMJ0YCTnFZGzp07Z96r/qyhQFsxqaXvVcPExx9/7FNdKV++vPkskztw4ICZfKzv7d///rcJdDrPRz9vd3ioUKGCec/qmWeeMZ+f3jScuJ08edIEHW0X6Wdbv379FM9P5yoVKVLEBJdr166Zba+//rppHU2aNEmKFSuW6vcKIIBcQCZ05swZl/7Pu3nz5qkav337djO+S5cuPtv79+9vtq9Zs8azrVSpUmbbunXrPNsSEhJcISEhrn79+nm2xcfHm3Fjx471OWaHDh3MMZIbPny4Ge82btw48/j48eM3PG/3a8ycOdOzrUqVKq6IiAjXyZMnPdt27NjhCg4OdrVv3/661+vUqZPPMR955BFXoUKFbvia3u8jd+7c5ufWrVu77r//fvPztWvXXJGRka4XXnghxc/g0qVLZkzy96Gf38iRIz3bNm/efN17c6tXr57ZN3369BT36c3bypUrzfiXXnrJdeDAAVeePHlcLVq0+NP3CMA5qLAgUzp79qy5z5s3b6rGL1u2zNxrNcJbv379zH3yuS4xMTGm5eKm/4LXdo1WD/zFPfflk08+kaSkpFQ958iRI2ZVjVZ7wsPDPdsrVapkqkHu9+mta9euPo/1fWn1wv0Zpoa2frSNc/ToUdOO0vuU2kFK223BwX/8p0crHvpa7nbXtm3bUv2aehxtF6WGLi3XlWJatdGKkLaItMoCIOMgsCBT0nkRSlsdqfHzzz+bX6I6r8VbZGSkCQ6631vJkiWvO4a2hU6dOiX+0qZNG9PG0VZV0aJFTWtq/vz5Nw0v7vPUX/7JaZvlxIkTcuHChZu+F30fKi3vpXHjxiYczps3z6wO0vknyT9LNz1/bZfdfvvtJnQULlzYBL7vvvtOzpw5k+rXvOWWW9I0wVaXVmuI00A3ceJEiYiISPVzAQQegQWZNrDo3IRdu3al6XnJJ73eSLZs2VLc7nK5/vJruOdXuIWFhcm6devMnJR27dqZX+gaYrRSknysFVbei5sGD61czJ49WxYuXHjD6op65ZVXTCVL56O89957snLlSjO5+I477kh1Jcn9+aTFt99+a+b1KJ0zAyBjIbAg09JJnXrROL0Wyp/RFT36y1JXtng7duyYWf3iXvHjD1rB8F5R45a8iqO06nP//febyanff/+9uQCdtly++OKLG74PtXfv3uv27dmzx1QzdOWQHTSkaCjQqlZKE5XdPvzwQzNBVldv6Tht1zRo0OC6zyS14TE1tKqk7SNt5ekkXl1BpiuZAGQcBBZkWgMHDjS/nLWlosEjOQ0zuoLE3dJQyVfyaFBQej0Rf9Fl09r60IqJ99wTrUwkX/6bnPsCasmXWrvp8m0do5UO7wCglSZdFeN+n3bQEKLLwidPnmxaaTer6CSv3ixYsEB+/fVXn23uYJVSuEurQYMGycGDB83non+muqxcVw3d6HME4DxcOA6ZlgYDXV6rbRSdv+F9pVtd5qu/JHVyqqpcubL5BaZXvdVfkLrEdtOmTeYXXIsWLW64ZPav0KqC/gJ95JFH5LnnnjPXPJk2bZqULVvWZ9KpThDVlpCGJa2caDtj6tSpUrx4cXNtlhsZO3asWe5bp04d6dy5s7kSri7f1Wus6DJnu2g1aMiQIamqfOl704qHLjnX9ozOe9El6Mn//HT+0PTp0838GA0wtWrVktKlS6fpvLQipZ/b8OHDPcusZ86caa7VMnToUFNtAZABBHqZEmC3//73v66nn37aFR0d7cqZM6crb968rrvvvts1adIks8TW7cqVK2YpbunSpV05cuRwlShRwhUXF+czRumS5CZNmvzpctobLWtWn332mevOO+8051OuXDnXe++9d92y5tWrV5tl2cWKFTPj9P7xxx837yf5ayRf+vv555+b9xgWFubKly+fq1mzZq7vv//eZ4z79ZIvm9Zj6XY9dmqXNd/IjZY16/LvqKgoc356nhs2bEhxOfInn3ziiomJcWXPnt3nfeq4O+64I8XX9D7O2bNnzZ9XtWrVzJ+vtz59+pil3vraAJwvSP9foEMTAADAzTCHBQAAOB6BBQAAOB6BBQAAOB6BBQAAOB6BBQAAOB6BBQAAOB6BBQAAOF6mvNJtWNUegT4FwJFObZ4c6FMAHCc0e8b5vXTx26z7d5gKCwAAcLxMWWEBAMBRgqgPWEVgAQDAbkFBgT6DDI/AAgCA3aiwWMYnCAAAHI8KCwAAdqMlZBmBBQAAu9ESsoxPEAAAOB4VFgAA7EZLyDICCwAAdqMlZBmfIAAAcDwqLAAA2I2WkGUEFgAA7EZLyDI+QQAA4HhUWAAAsBstIcsILAAA2I2WkGUEFgAA7EaFxTIiHwAAcDwqLAAA2I2WkGUEFgAA7EZgsYxPEAAAOB4VFgAA7BbMpFurCCwAANiNlpBlfIIAAMDxqLAAAGA3rsNiGYEFAAC70RKyjE8QAAA4HhUWAADsRkvIMgILAAB2oyVkGYEFAAC7UWGxjMgHAAAcjwoLAAB2oyVkGYEFAAC70RKyjMgHAAAcjwoLAAB2oyVkGYEFAAC70RKyjMgHAAAcjwoLAAB2oyVkGYEFAAC7EVgs4xMEACATGjFihAQFBfncypcv79l/6dIl6d69uxQqVEjy5MkjrVq1kmPHjvkc4+DBg9KkSRPJlSuXREREyIABA+Tq1as+Y9auXSvVqlWTkJAQKVOmjMyaNeu6c5kyZYpER0dLaGio1KpVSzZt2pTm90NgAQAgPSbd+uOWRnfccYccOXLEc/vqq688+/r06SOLFy+WBQsWyJdffimHDx+Wli1bevZfu3bNhJXLly/L+vXrZfbs2SaMDBs2zDMmPj7ejKlfv75s375devfuLV26dJGVK1d6xsybN0/69u0rw4cPl23btknlypWlUaNGkpCQkKb3EuRyuVySyYRV7RHoUwAc6dTmyYE+BcBxQtNhckRY89f9cpyLnzybpgrLokWLTJBI7syZM1KkSBGZM2eOtG7d2mzbs2ePVKhQQTZs2CC1a9eW5cuXS9OmTU2QKVq0qBkzffp0GTRokBw/flxy5sxpfl66dKns2rXLc+y2bdvK6dOnZcWKFeaxVlRq1Kghkyf/8d+fpKQkKVGihPTs2VMGDx6c6vdDhQUAgAxSYUlMTJSzZ8/63HTbjezbt0+KFSsmt956qzz55JOmxaO2bt0qV65ckQYNGnjGaruoZMmSJrAova9YsaInrCitjOhr7t692zPG+xjuMe5jaHVGX8t7THBwsHnsHpNaBBYAADKIUaNGSf78+X1uui0lWtnQFo5WOqZNm2baN/fee6+cO3dOjh49aiokBQoU8HmOhhPdp/TeO6y497v33WyMhpqLFy/KiRMnTGsppTHuY6QWq4QAAMggq4Ti4uLMfBBvOtk1JQ899JDn50qVKpkAU6pUKZk/f76EhYVJRkOFBQCADNISCgkJkXz58vncbhRYktNqStmyZWX//v0SGRlp2jU618SbrhLSfUrvk68acj/+szF6XhqKChcuLNmyZUtxjPsYqUVgAQAgCzh//rz8+OOPEhUVJbGxsZIjRw5ZvXq1Z//evXvNHJc6deqYx3q/c+dOn9U8q1atMmEkJibGM8b7GO4x7mNo20lfy3uMTrrVx+4xqUVLCAAAm+k1UNJb//79pVmzZqYNpCt9dFmxVjsef/xxM/elc+fOpr0UHh5uQoiu2tEQoSuEVMOGDU0wadeunYwZM8bMORkyZIi5dou7qtO1a1ez+mfgwIHSqVMnWbNmjWk56cohN32NDh06SPXq1aVmzZoyfvx4uXDhgnTs2DFN74fAAgBAJgwsv/zyiwknJ0+eNEuY77nnHtm4caP5WY0bN86s2NELxulKI13dM3XqVM/zNdwsWbJEunXrZoJM7ty5TfAYOXKkZ0zp0qVNONFrukyYMEGKFy8ub731ljmWW5s2bcwyaL1+i4aeKlWqmInAySfi/hmuwwJkIVyHBQjMdVhyt57pl+Nc+DBtVYnMhAoLAAB2S/8CS6ZDYAEAIBO2hDIbVgkBAADHo8ICAIDNqLBYR2ABAMBmBBbrCCwAANiMwGIdc1gAAIDjUWEBAMBuFFgsI7AAAGAzWkLW0RICAACOR4UFAACbUWGxjsACAIDNCCzW0RICAACOR4UFAACbUWGxjsACAIDdyCuW0RICAACOR4UFAACb0RKyjsACAIDNCCzWEVgAALAZgcU65rAAAADHo8ICAIDdKLBYRmABAMBmtISsoyUEAAAcjwoLAAA2o8JiHYEFAACbEVisoyUEAAAcjwoLAAA2o8JiHYEFAAC7kVcsoyUEAAAcjwoLAAA2oyVkHYEFAACbEVisI7AAAGAzAot1zGEBAACOR4UFAAC7UWCxjMACAIDNaAlZR0sIAAA4HhUWePzz2cYypGtjn217449KlZYveR7XqlRaRnRvKjUqRsu1a0ny3X9/lWb/mCKXEq/IvbG3y2dv9Urx2Pc8OUa2fn/Q/NzqgaoyoHMjub1khJw4fV6mf/CljHtntWdsZOF8MrpvS6kWU1JuK1FYps79Uga8+pFt7xuww0MP/E0OH/71uu1t2j4hzw8dLiNHDJNvNq6X4wkJkitXLqlcpar07ttfSt96W0DOF/aiwmIdgQU+du8/LE26TvI8vnotySesfDL5H/LqzM+k778WmH2Vyt4iSUkus3/jjgMS3SDO53jD/tFU6tcs5wkrDe+OkZkvPyV9xyyQzzf8IOVLR8rUYU/IxcQrMn3eOjMmZ47scuLUORn91grp+WT9dHrngH+9P+9DSbp2zfN4//598myXjvJAowfN45iYO6RJ02YSGRUlZ8+ckWlTJknXpzvLss9WS7Zs2QJ45rADgcU6Agt8aAg5dvJcivvG9GspUz9YK6/OXOXZtu/nBM/PV65e83lu9uzB0vS+SjLtgy89255oUlMWr90hb334lXn8068nZeyMz6TfUw94AsvBI79J/7F/VFQ6NK9jw7sE7BceHu7zeMZbb0iJEiWleo2a5nHrx9p49t1yS3Hp8VxvebRlczn8669SomTJdD9fwOkCGlhOnDghM2bMkA0bNsjRo0fNtsjISLnrrrvkqaeekiJFigTy9LKkMiWLyIHPXjYtnm++i5dhkz6VQ0dPSZGCeaRmpdLywfIt8sWsvlK6eGH570/HZMTkxbJ++4EUj9W0XiUplD+3vPvJRs+2kJzZ5feLl33GXUy8LMUjC0rJqHATVoDM5srly7J0yafSrkPHFP+l/fvvv8snCz+WW4oXN/8NROZDhSUDT7rdvHmzlC1bViZOnCj58+eXunXrmpv+rNvKly8vW7ZsCdTpZUmbd/0kzwx7Tx7uPkWee2WeRN9SSD6f0Ufy5AoxAcU9z2XGx+ulefepsv2HQ7Ls9Z5yW8mUg2WHFnVk1YYf5NeE055tq9b/IM3vryz31Sxr/gKXKRkhvf5+v9kXVSR/Or1TIH2tWfO5nDt3Th5u8YjP9nlz35fa1atKnRpV5auv1snrb86UHDlzBuw8YaMgP92ysIBVWHr27CmPPvqoTJ8+/brk6XK5pGvXrmaMVl9uJjEx0dx8np90TYKC6QGn1Wdff+/5ede+w7J550+yd9lIadWwmpl8q97+6Ct599M/KiY79v4i99UsZ9o2WonxdktEAXmgTgX5+6AZPttnfPy13Fq8sHw8oavkyJ5Nzl64JFPmrJWh3ZpIUtL/5ssAmcnCjz6Su++pKxERRX22N276sNS+6245cfy4zJ75tgzo11tmvzdXQkJCAnaugFMFrMKyY8cO6dOnT4plMt2m+7Zv3/6nxxk1apSpynjfrh7batNZZy1nzl+U/QcT5LYSReTI8bNm2w8H/ggubhpkSkQWvO657ZrXlpNnLsiSL7+7bt+QiZ9I4bv7SbnGwyS6wfOyZffPZnv8rydtey9AoOhKIV0N1LJ16+v25c2bV0qVipbY6jXktXETJT7+gKz5/H9zxJB56O81f9yysoAFFu3Tbtq06Yb7dV/Ror7/GklJXFycnDlzxueWvWisn882a8odltO0go6eOCM/Hz4phxNOS9noCJ8xZUpFpDjvpP3DtWXOkk1y9WrKVRNdWXT4+BkzUfexB2PNCqMTp87b9l6AQNG5KeHhheTeuvfddJxZa+dyyeXLvnO8kDkQWDJwS6h///7yzDPPyNatW+X+++/3hJNjx47J6tWr5c0335RXX331T4+jpdPk5VPaQX/NqD6PyNJ1O+Xg4d+kWER+GdK1iVxLSpL5K/6oWI2b/bnZtvO/v5p20N+b1ZJy0UXliQFv+xxH56do0Jm5cP11r1GoQG55pEFVWbdln4TmzC7tm9eWlg2qSsMuE3zG6XJplTtXiBQumMc8vnz1muxJVuEBnEzbnBpYmjVvIdmz/+8/t78cOiQrVyyTOnfdLQULhsuxY0fNKqKQkFC5p269gJ4z7JHFs0bGDizdu3eXwoULy7hx42Tq1Kly7f+vV6DXH4iNjZVZs2bJY489FqjTy5JuKVpA3hnVUcLz5zLVDl39U6/9a57Kx+Q5ayU0JIeM6ddKCubPZYJL026TJf6XEz7HearFXbJh+49mFVFKNOhoONK/wLoSqdHTEzxtIbdv5v3vei6xMSWlbeMapspTvslwW947YIeNG9bLkSOHpUXLVj7bc4bklG1bt8h7786Ws2fOSqHChSQ2trq88/5cKVSoUMDOF3CyIJfOcA2wK1eumCXOSkNMjhw5LB0vrGoPP50ZkLmc2jw50KcAOE5oOvzT/fYBK/xynH1j/7jwYFbkiAvHaUCJiooK9GkAAGALWkLW8eWHAADA8RxRYQEAIDPL6it8/IHAAgCAzcgr1tESAgAAjkeFBQAAmwUHU2KxisACAIDNaAlZR0sIAIAsYPTo0Wbyb+/evT3bLl26ZC7kqhcszJMnj7Rq1cpccd7bwYMHpUmTJpIrVy6JiIiQAQMGyNWrV33GrF27VqpVq2auPF+mTBlz8dfkpkyZItHR0RIaGiq1atW66dfzpITAAgBAJv8uoc2bN8vrr78ulSpV8tmuXzS8ePFiWbBggXz55Zdy+PBhadmypWe/XoVew4p+x9X69etl9uzZJowMGzbMMyY+Pt6MqV+/vvnSYg1EXbp0kZUrV3rGzJs3T/r27SvDhw+Xbdu2SeXKlaVRo0aSkJCQsa50629c6RZIGVe6BQJzpduKQ/3zLdw7X3wgzc85f/68qX7o1+C89NJLUqVKFRk/frz5suAiRYrInDlzpPX/f5v4nj17pEKFCrJhwwapXbu2LF++XJo2bWqCjPs7/6ZPny6DBg2S48ePS86cOc3PS5culV27dnles23btnL69GlZseKPK/xqRaVGjRoyefJkz/dslShRQnr27CmDBw9O1fugwgIAQAapsCQmJsrZs2d9brrtZrTloxWQBg0a+GzXLx/Wr8bx3l6+fHkpWbKkCSxK7ytWrOgJK0orI/q6u3fv9oxJfmwd4z6GVmf0tbzHBAcHm8fuMalBYAEAIIMYNWqU5M+f3+em227kgw8+MC2YlMYcPXrUVEgKFCjgs13Die5zj/EOK+797n03G6Oh5uLFi+a7ArW1lNIY9zFSg1VCAABkkCvdxsXFmbkg3nSia0oOHTokvXr1klWrVpmJrhkdgQUAgAyyrDkkJOSGASU5bcPopFadv+KmlY5169aZuSQ6KVbbNTrXxLvKoquEIiMjzc96n3w1j3sVkfeY5CuL9HG+fPkkLCxMsmXLZm4pjXEfIzVoCQEAkAndf//9snPnTrNyx32rXr26PPnkk56fc+TIIatXr/Y8Z+/evWYZc506dcxjvddjeK/m0YqNhpGYmBjPGO9juMe4j6Ftp9jYWJ8xOulWH7vHpAYVFgAAMuGXH+bNm1fuvPNOn225c+c211xxb+/cubNpMYWHh5sQoqt2NEToCiHVsGFDE0zatWsnY8aMMXNOhgwZYibyuis9Xbt2NRWbgQMHSqdOnWTNmjUyf/58s3LITV+jQ4cOJiTVrFnTrFK6cOGCdOzYMdXvh8ACAEAWvdLtuHHjzIodvWCcrjbS1T26/NlNWzlLliyRbt26mSCjgUeDx8iRIz1jSpcubcKJXtNlwoQJUrx4cXnrrbfMsdzatGljlkHr9Vs09OjSal3ynHwi7s1wHRYgC+E6LEBgrsNSbeQavxxn27C/SVZFhQUAgEzYEspsCCwAANiMvGIdq4QAAIDjUWEBAMBmtISsI7AAAGAz8op1BBYAAGxGhcU65rAAAADHo8ICAIDNKLBYR2ABAMBmtISsoyUEAAAcjwoLAAA2o8BiHYEFAACb0RKyjpYQAABwPCosAADYjAKLdQQWAABsRkvIOlpCAADA8aiwAABgMyos1hFYAACwGXnFOgILAAA2o8JiHXNYAACA41FhAQDAZhRYrCOwAABgM1pC1tESAgAAjkeFBQAAm1FgsY7AAgCAzYJJLJbREgIAAI5HhQUAAJtRYLGOwAIAgM1YJWQdgQUAAJsFk1csYw4LAABwPCosAADYjJaQdQQWAABsRl6xjpYQAABwPCosAADYLEgosVhFYAEAwGasErKOlhAAAHA8KiwAANiMVULWEVgAALAZecU6WkIAAMDxqLAAAGCzYEoslhFYAACwGXnFOgILAAA2Y9KtdcxhAQAAjkeFBQAAm1FgsY7AAgCAzZh0ax0tIQAA4HhUWAAAsBn1FesILAAA2IxVQtbREgIAAI5HhQUAAJsFU2BJn8Dy6aefpvqADz/8sJXzAQAg06EllE6BpUWLFqn+A7l27ZrVcwIAAEh7YElKSkrNMAAAkAIKLNYxhwUAAJvREgrQKqELFy7IsmXLZPr06TJx4kSfGwAAuH7SrT9uaTFt2jSpVKmS5MuXz9zq1Kkjy5cv9+y/dOmSdO/eXQoVKiR58uSRVq1aybFjx3yOcfDgQWnSpInkypVLIiIiZMCAAXL16lWfMWvXrpVq1apJSEiIlClTRmbNmnXduUyZMkWio6MlNDRUatWqJZs2bRLbKyzffvutNG7cWH7//XcTXMLDw+XEiROeN/Pcc8+l+SQAAIB/FS9eXEaPHi233367uFwumT17tjRv3tz8Hr/jjjukT58+snTpUlmwYIHkz59fevToIS1btpSvv/7aPF/npGpYiYyMlPXr18uRI0ekffv2kiNHDnnllVfMmPj4eDOma9eu8v7778vq1aulS5cuEhUVJY0aNTJj5s2bJ3379jVFDg0r48ePN/v27t1rckNqBbn0XaTBfffdJ2XLljUvrG9wx44d5uT//ve/S69evcybDbSwqj0CfQqAI53aPDnQpwA4Tmg6TI7o+MFOvxxnZtuKlp6vRYaxY8dK69atpUiRIjJnzhzzs9qzZ49UqFBBNmzYILVr1zbVmKZNm8rhw4elaNGiZoz+7h80aJAcP35ccubMaX7W0LNr1y7Pa7Rt21ZOnz4tK1asMI81pNSoUUMmT57smRdbokQJ6dmzpwwePNi+ltD27dulX79+EhwcLNmyZZPExETzwmPGjJHnn38+rYcDACDTC/LT7a/SaskHH3xgOiPaGtq6datcuXJFGjRo4BlTvnx5KVmypAksSu8rVqzoCStKKyNnz56V3bt3e8Z4H8M9xn2My5cvm9fyHqP5QR+7x6RWmnOlVlP0xZSWcrS/pYlMqy2HDh1K6+EAAEAqJSYmmps3nTuit5Ts3LnTBBSdr6LzVBYuXCgxMTGm+KAVkgIFCviM13By9OhR87Pee4cV9373vpuN0VBz8eJFOXXqlAlLKY3Rik5apLnCUrVqVdm8ebP5uV69ejJs2DDTt+rdu7fceeedaT0cAACZXnBQkF9uo0aNMgUC75tuu5Fy5cqZcPLNN99It27dpEOHDvL9999LRpTmCotOtDl37pz5+eWXXzYTcPRD0Ek9M2bMsOMcAQDI0Py1qjkuLs5MYPV2o+qK0iqKrtxRsbGxpuAwYcIEadOmjWnX6FwT7yqLrhLSSbZK75Ov5nGvIvIek3xlkT7WVUlhYWFm6ojeUhrjPoZtFZbq1atL/fr1PS0hnVSjpR/tUVWuXDmthwMAAKkUEhLiWabsvt0ssCSnE161paThRad46KoeN121o9M8tIWk9F5bSgkJCZ4xq1atMq+pbSX3GO9juMe4j6GBSV/Le4yegz52j0ktLhwHAEAmvHBcXFycPPTQQ2YirXZGdEWQXjNl5cqVppXUuXNnU63RlUMaQnTVjoYIXSGkGjZsaIJJu3btzMIana8yZMgQc+0Wd0jS5cy6+mfgwIHSqVMnWbNmjcyfP9+sHHLT19BWlBY8atasaZY16+Tfjh072htYSpcufdMP/sCBA2k9JAAAmVogLnSbkJBgpm3o9VM0oOhF5DSsPPDAA2b/uHHjzCIavWCcVl10dc/UqVM9z9dWzpIlS8y0Dw0yuXPnNsFj5MiRPplAw4le00VbTXrtl7feestzDRal7SddBq1zXjX0VKlSxXRnkk/E9ft1WPSEvOmyKL0Ijb64XgEvLWuq7cJ1WICUcR0WIDDXYXn2wz+WAVv1eus7JKtK8x+TXhwuJXrZ3S1btvjjnAAAyFR0hQ8C8F1CKdE+2UcffeSvwwEAkGloXvHHLSvzWyHsww8/NBN3AACAL76tOQCBRS8c5/3B6xQYnUSjE2q8J+sAAAAELLDoNz16BxadYaxfoKRfiqjfQ+AETCwEAGTK+RdZWJoDy4gRI+w5EwAAMilaQgEIfbou2/uqd24nT540+wAAAAJeYbnRZVv0ojN6CV4AAOArmAJL+gWWiRMnespaehU7/ZpqN/3q6HXr1jlmDgsAAE5CYEnHwKKX8HVXWKZPn+7T/tHKSnR0tNkOAAAQsMASHx9v7vWbmj/++GMpWLCg308GAIDMiEm3AZjD8sUXX/jhZQEAyDpoCQVglZB+q+O//vWv67brV08/+uijfjglAAAAi4FFJ9c2btw4xe8S0n0AAMAX3yUUgJbQ+fPnU1y+nCNHDjl79qwfTgkAgMyFb2sOQIWlYsWKMm/evOu2f/DBBxITE+OHUwIAIPP9svXHLStLc4Vl6NCh0rJlS/nxxx/lb3/7m9m2evVqmTNnjvnGZgAAgIAHlmbNmsmiRYvklVdeMQElLCxMKleuLGvWrJHw8HC/nyAAABkdHSHrglw3utZ+Kum8lblz58rbb78tW7duNVe9DbRLVwN9BgCAjCI0zf90T7uhK/b55TgvPni7ZFV/uSWmK4I6dOggxYoVk9dee820hzZu3OjfswMAAEhrS+jo0aMya9YsU03Ryspjjz1mvvRQW0RMuAUAIGW0hNKxwqJzV8qVKyffffedjB8/Xg4fPiyTJk3ywykAAJD5r3Trj1tWluoKy/Lly+W5556Tbt26ye23Z90eGgAAcHCF5auvvpJz585JbGys1KpVSyZPniwnTpyw9+wAAMgkF47zxy0rS3VgqV27trz55pty5MgRefbZZ82F4nTCbVJSkqxatcqEGQAAcD0uzR+AVUK5c+eWTp06mYrLzp07pV+/fjJ69GiJiIiQhx9+2A+nBAAA4MvSlX51Eq5+S/Mvv/xirsUCAACux6RbB1w4zom4cBwAwEkXjntl9Y9+Oc7z998mWVU6/DEBAJC1ZfXqiD9k9S9/BAAAGQAVFgAAbEaFxToCCwAANgvK6muS/YCWEAAAcDwqLAAA2IyWkHUEFgAAbEZHyDpaQgAAwPGosAAAYLOs/sWF/kBgAQDAZsxhsY6WEAAAcDwqLAAA2IyOkHUEFgAAbBYsJBarCCwAANiMCot1zGEBAACOR4UFAACbsUrIOgILAAA24zos1tESAgAAjkeFBQAAm1FgsY7AAgCAzWgJWUdLCAAAOB4VFgAAbEaBxToCCwAANqOdYR2fIQAAcDwqLAAA2CyInpBlBBYAAGxGXLGOlhAAAOmwrNkft7QYNWqU1KhRQ/LmzSsRERHSokUL2bt3r8+YS5cuSffu3aVQoUKSJ08eadWqlRw7dsxnzMGDB6VJkyaSK1cuc5wBAwbI1atXfcasXbtWqlWrJiEhIVKmTBmZNWvWdeczZcoUiY6OltDQUKlVq5Zs2rQpTe+HwAIAQCb05ZdfmjCyceNGWbVqlVy5ckUaNmwoFy5c8Izp06ePLF68WBYsWGDGHz58WFq2bOnZf+3aNRNWLl++LOvXr5fZs2ebMDJs2DDPmPj4eDOmfv36sn37dundu7d06dJFVq5c6Rkzb9486du3rwwfPly2bdsmlStXlkaNGklCQkKq30+Qy+VySSZzyTf4AQBwQ6HpMDni/a2/+OU4T8YW/8vPPX78uKmQaDCpW7eunDlzRooUKSJz5syR1q1bmzF79uyRChUqyIYNG6R27dqyfPlyadq0qQkyRYsWNWOmT58ugwYNMsfLmTOn+Xnp0qWya9cuz2u1bdtWTp8+LStWrDCPtaKi1Z7Jkyebx0lJSVKiRAnp2bOnDB48OFXnT4UFAACbaTfHHzcrNKCo8PBwc79161ZTdWnQoIFnTPny5aVkyZImsCi9r1ixoiesKK2MnD17Vnbv3u0Z430M9xj3MbQ6o6/lPSY4ONg8do9JDSbdAgCQQSQmJpqbN503oreb0YqGtmruvvtuufPOO822o0ePmgpJgQIFfMZqONF97jHeYcW9373vZmM01Fy8eFFOnTplWkspjdGKTmpRYQEAIB2WNfvjNmrUKMmfP7/PTbf9GZ3Loi2bDz74QDIqKiwAANjMX9WBuLg4M3nV259VV3r06CFLliyRdevWSfHi/5sDExkZado1OtfEu8qiq4R0n3tM8tU87lVE3mOSryzSx/ny5ZOwsDDJli2buaU0xn2M1KDCAgBABhESEmKCgPftRoFF19RoWFm4cKGsWbNGSpcu7bM/NjZWcuTIIatXr/Zs02XPuoy5Tp065rHe79y502c1j6440teNiYnxjPE+hnuM+xjadtLX8h6jLSp97B6TGlRYAADIhFe67d69u1kB9Mknn5hrsbjnnGgbSSsfet+5c2dTsdGJuBpCdNWOhghdIaR0GbQGk3bt2smYMWPMMYYMGWKO7Q5KXbt2Nat/Bg4cKJ06dTLhaP78+WblkJu+RocOHaR69epSs2ZNGT9+vFle3bFjx1S/H5Y1AwCytPRY1rxg+2G/HOfRKsUsh6SZM2fKU0895blwXL9+/WTu3LlmMq+u7pk6dapPq+bnn3+Wbt26mYvD5c6d2wSP0aNHS/bs//vgdJ9e0+X77783baehQ4d6XsNNQ83YsWNN6KlSpYpMnDjRLHdO9fshsAAAsrLMGlgyG1pCAADYjC8/tI7AAgCAzVjhYh2BBQAAm1FhsY7QBwAAHI8KCwAANqO+Yh2BBQAAm9ERso6WEAAAcDwqLAAA2CyYppBlBBYAAGxGS8g6WkIAAMDxqLAAAGCzIFpClhFYAACwGS0h62gJAQAAx6PCAgCAzVglZB2BBQAAm9ESso7AAgCAzQgs1jGHBQAAOB4VFgAAbMayZusILAAA2CyYvGIZLSEAAOB4VFgAALAZLSHrCCwAANiMVULW0RICAACOR4UFAACb0RKyjsACAIDNWCVkHS0hAADgeFRYYNlDD/xNDh/+9brtbdo+Ic8PHS4jRwyTbzaul+MJCZIrVy6pXKWq9O7bX0rfeltAzhdID2+/+bqsXvWZxMcfkJDQUKny//+7jy59q2dM56fayZbNm3ye1/qxNjJ0+MgAnDHsREvIOgILLHt/3oeSdO2a5/H+/fvk2S4d5YFGD5rHMTF3SJOmzSQyKkrOnjkj06ZMkq5Pd5Zln62WbNmyBfDMAftoEGnz+JNyR8WKcu3qNZk04d/mf/cff7rUBHe3Vq0fk3/0eM7zODQsLEBnDDuxSsg6AgssCw8P93k84603pESJklK9Rk3PvxjdbrmluPR4rrc82rK5HP71VylRsmS6ny+QHqa98bbP45Evj5b699aRH77fLbHVa3i2h4aGSuEiRQJwhkhP5BXrmMMCv7py+bIsXfKptGjZSoJS+CfF77//Lp8s/FhuKV5cIiMjA3KOQCCcP3fO3OfLn99n+7Kli6Xe3bWkZfOmMmHca3Lx4sUAnSHgbI6usBw6dEiGDx8uM2bMuOGYxMREc/PmyhYiISEh6XCGSG7Nms/l3Llz8nCLR3y2z5v7vox77VW5ePF3iS5dWl5/c6bkyJkzYOcJpKekpCQZ869XpErVanL77WU92x9q3FSiihWTiIgI+e9/98r4f78qP/0UL+MmTA7o+cL/gukJWRbkcrlc4lA7duyQatWqyTWv+RHJjRgxQl544QWfbf8cOlyGDBuRDmeI5LRHnyNHDpk0dbrPdg0xv/12Uk4cPy6zZ74tCQkJMvu9uQRLZAkvjRwuX//nPzLr3TlS9CaVxW82bpBnOj8lS5avol2ajkLT4Z/uG/ef9stxapcpIFlVQCssn3766U33Hzhw4E+PERcXJ3379r2uwoL0pyuFdDXQvydMum5f3rx5za1UqWipVKmy3HNXTVnz+Sp5qEnTgJwrkF5eeWmkrPtyrcyY/d5Nw4qqWKmyuT948GcCC+CkwNKiRQszz+FmRZ6U5kF403+hJ/9X+qWrfjtFpIHOTQkPLyT31r3vpuPMn7bLJZcvX06vUwPSnf53bdTLL8qa1avk7VnvSvHiJf70OXv3/GDuizAJN/OhI5SxA0tUVJRMnTpVmjdvnuL+7du3S2xsbLqfF/5aj14DS7PmLSR79v/9z+qXQ4dk5YplUueuu6VgwXA5duyoWUUUEhIq99StF9BzBuz0yosvyPJlS2T8pKmSO1du0w5VefLmNSuDDh08aCbc3lu3nuQvUED27d0rY8eMMiuIypYrH+jTh59xHZYMHlg0jGzduvWGgeXPqi9wjo0b1suRI4fN6iBvOUNyyratW+S9d2fL2TNnpVDhQhIbW13eeX+uFCpUKGDnC9ht/ry5novDeRv50ihp/khLM9dL56y8/+47ZjJ6ZGSUNGjQUJ7u+o8AnTHgbAGddPuf//xHLly4IA8++McFxpLTfVu2bJF69dL2L3FaQgAAJ0263XTgjF+OU/NW32XxWYmjVwn9VQQWAICTAstmPwWWGlk4sHDhOAAA4HiOvnAcAACZAnNuLSOwAABgM1YJWUdgAQDAZlyZ3zrmsAAAAMejwgIAgM0osFhHYAEAwG4kFstoCQEAAMejwgIAgM1YJWQdgQUAAJuxSsg6WkIAAMDxqLAAAGAzCizWEVgAALAbicUyWkIAAMDxqLAAAGAzVglZR2ABAMBmrBKyjpYQAAA2C/LTLa3WrVsnzZo1k2LFiklQUJAsWrTIZ7/L5ZJhw4ZJVFSUhIWFSYMGDWTfvn0+Y3777Td58sknJV++fFKgQAHp3LmznD9/3mfMd999J/fee6+EhoZKiRIlZMyYMdedy4IFC6R8+fJmTMWKFWXZsmVpei8EFgAAMqkLFy5I5cqVZcqUKSnu12AxceJEmT59unzzzTeSO3duadSokVy6dMkzRsPK7t27ZdWqVbJkyRITgp555hnP/rNnz0rDhg2lVKlSsnXrVhk7dqyMGDFC3njjDc+Y9evXy+OPP27CzrfffistWrQwt127dqX6vQS5NF5lMpeuBvoMAAAZRWg6TI7Y9atvReKvuvOWPH/5uVphWbhwoQkKSn/9a+WlX79+0r9/f7PtzJkzUrRoUZk1a5a0bdtWfvjhB4mJiZHNmzdL9erVzZgVK1ZI48aN5ZdffjHPnzZtmvzzn/+Uo0ePSs6cOc2YwYMHm2rOnj17zOM2bdqY8KSBx6127dpSpUoVE5ZSgwoLAADpMOnWH//nT/Hx8SZkaBvILX/+/FKrVi3ZsGGDeaz32gZyhxWl44ODg01Fxj2mbt26nrCitEqzd+9eOXXqlGeM9+u4x7hfJzWYdAsAQAaRmJhobt5CQkLMLa00rCitqHjTx+59eh8REeGzP3v27BIeHu4zpnTp0tcdw72vYMGC5v5mr5MaVFgAAEiHVUL+uI0aNcpUQbxvui0roMICAIDN/NXMiYuLk759+/ps+yvVFRUZGWnujx07ZlYJueljnVviHpOQkODzvKtXr5qVQ+7n670+x5v78Z+Nce9PDSosAABkECEhIWZ5sfftrwYWbeNoYFi9erXPih+dm1KnTh3zWO9Pnz5tVv+4rVmzRpKSksxcF/cYXTl05coVzxhdUVSuXDnTDnKP8X4d9xj366QGgQUAgEx6IZbz58/L9u3bzc090VZ/PnjwoFk11Lt3b3nppZfk008/lZ07d0r79u3Nyh/3SqIKFSrIgw8+KE8//bRs2rRJvv76a+nRo4dZQaTj1BNPPGEm3OqSZV3+PG/ePJkwYYJPJahXr15mddFrr71mVg7psuctW7aYY6X6I2RZMwAgK0uPZc17jvzul+OUj8qVpvFr166V+vXrX7e9Q4cOZumyRoDhw4eba6ZoJeWee+6RqVOnStmyZT1jtf2jwWLx4sVmdVCrVq3MtVvy5Mnjc+G47t27m+XPhQsXlp49e8qgQYOuu3DckCFD5KeffpLbb7/dXANGl0enFoEFAJClZebAkpkw6RYAAJvxXULWEVgAALAZecU6AgsAAHYjsVjGKiEAAOB4VFgAALCZv78HKCsisAAAYDMm3VpHSwgAADgeFRYAAGxGgcU6AgsAAHYjsVhGSwgAADgeFRYAAGzGKiHrCCwAANiMVULW0RICAACOR4UFAACbUWCxjsACAIDdSCyWEVgAALAZk26tYw4LAABwPCosAADYjFVC1hFYAACwGXnFOlpCAADA8aiwAABgM1pC1hFYAACwHYnFKlpCAADA8aiwAABgM1pC1hFYAACwGXnFOlpCAADA8aiwAABgM1pC1hFYAACwGd8lZB2BBQAAu5FXLGMOCwAAcDwqLAAA2IwCi3UEFgAAbMakW+toCQEAAMejwgIAgM1YJWQdgQUAALuRVyyjJQQAAByPCgsAADajwGIdgQUAAJuxSsg6WkIAAMDxqLAAAGAzVglZR2ABAMBmtISsoyUEAAAcj8ACAAAcj5YQAAA2oyVkHYEFAACbMenWOlpCAADA8aiwAABgM1pC1hFYAACwGXnFOlpCAADA8aiwAABgN0oslhFYAACwGauErKMlBAAAHI8KCwAANmOVkHUEFgAAbEZesY7AAgCA3UgsljGHBQAAOB4VFgAAbMYqIesILAAA2IxJt9bREgIAAI4X5HK5XIE+CWROiYmJMmrUKImLi5OQkJBAnw7gGPzdANKOwALbnD17VvLnzy9nzpyRfPnyBfp0AMfg7waQdrSEAACA4xFYAACA4xFYAACA4xFYYBudTDh8+HAmFQLJ8HcDSDsm3QIAAMejwgIAAByPwAIAAByPwAIAAByPwAIAAByPwALbTJkyRaKjoyU0NFRq1aolmzZtCvQpAQG1bt06adasmRQrVkyCgoJk0aJFgT4lIMMgsMAW8+bNk759+5qlm9u2bZPKlStLo0aNJCEhIdCnBgTMhQsXzN8FDfMA0oZlzbCFVlRq1KghkydPNo+TkpKkRIkS0rNnTxk8eHCgTw8IOK2wLFy4UFq0aBHoUwEyBCos8LvLly/L1q1bpUGDBp5twcHB5vGGDRsCem4AgIyJwAK/O3HihFy7dk2KFi3qs10fHz16NGDnBQDIuAgsAADA8Qgs8LvChQtLtmzZ5NixYz7b9XFkZGTAzgsAkHERWOB3OXPmlNjYWFm9erVnm0661cd16tQJ6LkBADKm7IE+AWROuqS5Q4cOUr16dalZs6aMHz/eLOns2LFjoE8NCJjz58/L/v37PY/j4+Nl+/btEh4eLiVLlgzouQFOx7Jm2EaXNI8dO9ZMtK1SpYpMnDjRLHcGsqq1a9dK/fr1r9uu4X7WrFkBOScgoyCwAAAAx2MOCwAAcDwCCwAAcDwCCwAAcDwCCwAAcDwCCwAAcDwCCwAAcDwCCwAAcDwCC5AJPfXUU9KiRQvP4/vuu0969+4dkAulBQUFyenTp9P9tQFkLgQWIJ2DhP4C15t+51KZMmVk5MiRcvXqVVtf9+OPP5YXX3wxVWMJGQCciO8SAtLZgw8+KDNnzpTExERZtmyZdO/eXXLkyCFxcXE+4y5fvmxCjT/od9UAQEZGhQVIZyEhIRIZGSmlSpWSbt26SYMGDeTTTz/1tHFefvllKVasmJQrV86MP3TokDz22GNSoEABEzyaN28uP/30k+d4165dM182qfsLFSokAwcOlOTfuJG8JaRhadCgQVKiRAlzPlrpefvtt81x3d91U7BgQVNp0fNyf+P2qFGjpHTp0hIWFiaVK1eWDz/80Od1NICVLVvW7NfjeJ8nAFhBYAECTH+5azVFrV69Wvbu3SurVq2SJUuWyJUrV6RRo0aSN29e+c9//iNff/215MmTx1Rp3M957bXXzBfnzZgxQ7766iv57bffZOHChTd9zfbt28vcuXPNF1L+8MMP8vrrr5vjaoD56KOPzBg9jyNHjsiECRPMYw0r77zzjkyfPl12794tffr0kb///e/y5ZdfeoJVy5YtpVmzZuYbiLt06SKDBw+2+dMDkGXolx8CSB8dOnRwNW/e3PyclJTkWrVqlSskJMTVv39/s69o0aKuxMREz/h3333XVa5cOTPWTfeHhYW5Vq5caR5HRUW5xowZ49l/5coVV/HixT2vo+rVq+fq1auX+Xnv3r1afjGvnZIvvvjC7D916pRn26VLl1y5cuVyrV+/3mds586dXY8//rj5OS4uzhUTE+Ozf9CgQdcdCwD+CuawAOlMKydazdDqibZZnnjiCRkxYoSZy1KxYkWfeSs7duyQ/fv3mwqLt0uXLsmPP/4oZ86cMVWQWrVqefZlz55dqlevfl1byE2rH9myZZN69eql+pz1HH7//Xd54IEHfLZrladq1armZ63UeJ+HqlOnTqpfAwBuhsACpDOd2zFt2jQTTHSuigYMt9y5c/uMPX/+vMTGxsr7779/3XGKFCnyl1tQaaXnoZYuXSq33HKLzz6dAwMAdiOwAOlMQ4lOck2NatWqybx58yQiIkLy5cuX4pioqCj55ptvpG7duuaxLpHeunWreW5KtIqjlR2de6ITfpNzV3h0Mq9bTEyMCSYHDx68YWWmQoUKZvKwt40bN6bqfQLAn2HSLeBgTz75pBQuXNisDNJJt/Hx8eY6Kc8995z88ssvZkyvXr1k9OjRsmjRItmzZ4/84x//uOk1VKKjo6VDhw7SqVMn8xz3MefPn2/26+olXR2kravjx4+b6oq2pPr3728m2s6ePdu0o7Zt2yaTJk0yj1XXrl1l3759MmDAADNhd86cOWYyMAD4A4EFcLBcuXLJunXrpGTJkmYFjlYxOnfubOawuCsu/fr1k3bt2pkQonNGNFw88sgjNz2utqRat25twk358uXl6aeflgsXLph92vJ54YUXzAqfokWLSo8ePcx2vfDc0KFDzWohPQ9dqaQtIl3mrPQcdYWRhiBd8qyriV555RXbPyMAWUOQzrwN9EkAAADcDBUWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAADgeAQWAAAgTvd/wXgNvwCgr94AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roc = roc_auc_score(y_test, anomaly_scores)\n",
    "pr_auc = average_precision_score(y_test, anomaly_scores)\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(confusion_matrix(y_test, pred_labels), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292574f",
   "metadata": {},
   "source": [
    "So, we can see that this model does not perform particularly well, especially when compared to the 0.76 PR AUC of our quick Logistic Regression model from EDA. Let's try tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436486fa",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d33a90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(y_true, scores, k=0.01):\n",
    "    \"\"\"\n",
    "    Compute Precision@k and Recall@k for anomaly scores.\n",
    "    y_true: array-like of shape (n,) with 0/1 labels\n",
    "    scores: array-like of shape (n,) with higher = more anomalous\n",
    "    k: fraction of samples to flag (e.g. 0.01 = top 1%)\n",
    "    \"\"\"\n",
    "    n = len(scores)\n",
    "    top_n = max(1, int(np.ceil(k * n)))  # at least one sample\n",
    "\n",
    "    # Get indices of top-k scores\n",
    "    idx = np.argsort(-scores)[:top_n]\n",
    "\n",
    "    # Precision = frauds / flagged\n",
    "    precision = y_true.iloc[idx].mean()\n",
    "\n",
    "    # Recall = frauds caught / total frauds\n",
    "    recall = y_true.iloc[idx].sum() / y_true.sum()\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c8e63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def tune_IF(param_grid, PRIMARY, SECONDARY, X_test=X_test, y_test=y_test):\n",
    "\n",
    "    runs = []\n",
    "    best_tuple = (-np.inf, -np.inf)  # (primary, secondary)\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_scores = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        iso = IsolationForest(max_features=1, random_state=42, n_jobs=-1, **params) # Used param_grid to work out max_features = 1 is optimal\n",
    "        iso.fit(X_train)\n",
    "\n",
    "        scores = -iso.score_samples(X_test)\n",
    "\n",
    "        roc = roc_auc_score(y_test, scores)\n",
    "        pr_auc = average_precision_score(y_test, scores)\n",
    "        p_at_1, r_at_1 = precision_recall_at_k(y_test, scores, k=0.01)\n",
    "        p_at_05, r_at_05 = precision_recall_at_k(y_test, scores, k=0.005)\n",
    "\n",
    "        runs.append({**params, \"ROC\": roc, \"pr_auc\": pr_auc, \"p_at_1\": p_at_1, \"r_at_1\": r_at_1, \"p_at_05\": p_at_05, \"r_at_05\": r_at_05})\n",
    "\n",
    "        primary_val = r_at_1 if PRIMARY == \"r_at_1\" else pr_auc\n",
    "        secondary_val = pr_auc if SECONDARY == \"pr_auc\" else r_at_1\n",
    "        cand_tuple = (primary_val, secondary_val)\n",
    "\n",
    "        if cand_tuple > best_tuple:\n",
    "            best_tuple = cand_tuple\n",
    "            best_params = params\n",
    "            best_model = iso\n",
    "            best_scores = scores\n",
    "\n",
    "    results_df = pd.DataFrame(runs).sort_values(\n",
    "        by=[PRIMARY, SECONDARY], ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"Top configs:\")\n",
    "    display(results_df.head(20))\n",
    "    print(\"\\nSelected params:\", best_params)\n",
    "    print(f\"Selected {PRIMARY}={best_tuple[0]:.4f}, {SECONDARY}={best_tuple[1]:.4f}\")\n",
    "\n",
    "    return(best_tuple, best_params, best_model, best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63973672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_05</th>\n",
       "      <th>r_at_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>500</td>\n",
       "      <td>0.951356</td>\n",
       "      <td>0.254046</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>400</td>\n",
       "      <td>0.951046</td>\n",
       "      <td>0.249886</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>600</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.254707</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>500</td>\n",
       "      <td>0.949257</td>\n",
       "      <td>0.250248</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>400</td>\n",
       "      <td>0.949253</td>\n",
       "      <td>0.249883</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.185965</td>\n",
       "      <td>0.540816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>500</td>\n",
       "      <td>0.951684</td>\n",
       "      <td>0.256555</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>400</td>\n",
       "      <td>0.951567</td>\n",
       "      <td>0.256391</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>500</td>\n",
       "      <td>0.951413</td>\n",
       "      <td>0.256315</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>0.951482</td>\n",
       "      <td>0.255515</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>400</td>\n",
       "      <td>0.950580</td>\n",
       "      <td>0.254539</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>600</td>\n",
       "      <td>0.951035</td>\n",
       "      <td>0.252195</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946984</td>\n",
       "      <td>0.252221</td>\n",
       "      <td>0.119298</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>400</td>\n",
       "      <td>0.947780</td>\n",
       "      <td>0.252139</td>\n",
       "      <td>0.119298</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>400</td>\n",
       "      <td>0.954442</td>\n",
       "      <td>0.244785</td>\n",
       "      <td>0.119298</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>600</td>\n",
       "      <td>0.947404</td>\n",
       "      <td>0.249195</td>\n",
       "      <td>0.117544</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>600</td>\n",
       "      <td>0.952948</td>\n",
       "      <td>0.249076</td>\n",
       "      <td>0.117544</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>500</td>\n",
       "      <td>0.953923</td>\n",
       "      <td>0.249134</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.561224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap  max_samples  n_estimators       ROC    pr_auc    p_at_1  \\\n",
       "0        True         4096           500  0.951356  0.254046  0.124561   \n",
       "1        True         4096           400  0.951046  0.249886  0.124561   \n",
       "2        True         5120           600  0.948125  0.245399  0.124561   \n",
       "3        True         4096           600  0.951181  0.254707  0.122807   \n",
       "4        True         5120           500  0.949257  0.250248  0.122807   \n",
       "5        True         5120           400  0.949253  0.249883  0.122807   \n",
       "6       False         5120           500  0.951684  0.256555  0.121053   \n",
       "7       False         5120           400  0.951567  0.256391  0.121053   \n",
       "8        True         3072           500  0.951413  0.256315  0.121053   \n",
       "9       False         5120           600  0.951482  0.255515  0.121053   \n",
       "10       True         3072           400  0.950580  0.254539  0.121053   \n",
       "11       True         3072           600  0.951035  0.252195  0.121053   \n",
       "12      False         3072           500  0.946984  0.252221  0.119298   \n",
       "13      False         3072           400  0.947780  0.252139  0.119298   \n",
       "14      False         4096           400  0.954442  0.244785  0.119298   \n",
       "15      False         3072           600  0.947404  0.249195  0.117544   \n",
       "16      False         4096           600  0.952948  0.249076  0.117544   \n",
       "17      False         4096           500  0.953923  0.249134  0.115789   \n",
       "\n",
       "      r_at_1   p_at_05   r_at_05  \n",
       "0   0.724490  0.192982  0.561224  \n",
       "1   0.724490  0.192982  0.561224  \n",
       "2   0.724490  0.178947  0.520408  \n",
       "3   0.714286  0.189474  0.551020  \n",
       "4   0.714286  0.182456  0.530612  \n",
       "5   0.714286  0.185965  0.540816  \n",
       "6   0.704082  0.192982  0.561224  \n",
       "7   0.704082  0.192982  0.561224  \n",
       "8   0.704082  0.182456  0.530612  \n",
       "9   0.704082  0.192982  0.561224  \n",
       "10  0.704082  0.182456  0.530612  \n",
       "11  0.704082  0.182456  0.530612  \n",
       "12  0.693878  0.182456  0.530612  \n",
       "13  0.693878  0.189474  0.551020  \n",
       "14  0.693878  0.189474  0.551020  \n",
       "15  0.683673  0.182456  0.530612  \n",
       "16  0.683673  0.189474  0.551020  \n",
       "17  0.673469  0.192982  0.561224  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected params: {'bootstrap': True, 'max_samples': 4096, 'n_estimators': 500}\n",
      "Selected r_at_1=0.7245, pr_auc=0.2540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7244897959183674, 0.25404633106508606),\n",
       " {'bootstrap': True, 'max_samples': 4096, 'n_estimators': 500},\n",
       " IsolationForest(bootstrap=True, max_features=1, max_samples=4096,\n",
       "                 n_estimators=500, n_jobs=-1, random_state=42),\n",
       " array([0.44000145, 0.46177124, 0.48602979, ..., 0.43635305, 0.42253589,\n",
       "        0.42312922]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRIMARY = \"r_at_1\"\n",
    "SECONDARY = \"pr_auc\"\n",
    "\n",
    "# Note that I have already narrowed down the param_grid through multiple iterations\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [400, 500, 600],\n",
    "    \"max_samples\": [3072, 4096, 5120],\n",
    "    \"bootstrap\": [False, True],\n",
    "    # Note: intentionally not tuning 'contamination' here\n",
    "}\n",
    "\n",
    "tune_IF(param_grid, PRIMARY, SECONDARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf2e16",
   "metadata": {},
   "source": [
    "Now let's try out some of the best parameters on the test set to see how effective they are on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008ef8d",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c7615e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_05</th>\n",
       "      <th>r_at_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>0.945589</td>\n",
       "      <td>0.241527</td>\n",
       "      <td>0.114426</td>\n",
       "      <td>0.662602</td>\n",
       "      <td>0.180351</td>\n",
       "      <td>0.522358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>500</td>\n",
       "      <td>0.948059</td>\n",
       "      <td>0.240779</td>\n",
       "      <td>0.114075</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.181053</td>\n",
       "      <td>0.524390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>600</td>\n",
       "      <td>0.947024</td>\n",
       "      <td>0.238009</td>\n",
       "      <td>0.114075</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.518293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>4096</td>\n",
       "      <td>400</td>\n",
       "      <td>0.947488</td>\n",
       "      <td>0.234578</td>\n",
       "      <td>0.114075</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.518293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>0.946432</td>\n",
       "      <td>0.233266</td>\n",
       "      <td>0.114075</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.177544</td>\n",
       "      <td>0.514228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>500</td>\n",
       "      <td>0.945856</td>\n",
       "      <td>0.244157</td>\n",
       "      <td>0.113373</td>\n",
       "      <td>0.656504</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.518293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>5120</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945553</td>\n",
       "      <td>0.242472</td>\n",
       "      <td>0.113022</td>\n",
       "      <td>0.654472</td>\n",
       "      <td>0.180351</td>\n",
       "      <td>0.522358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>500</td>\n",
       "      <td>0.947182</td>\n",
       "      <td>0.235974</td>\n",
       "      <td>0.112671</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.178246</td>\n",
       "      <td>0.516260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>600</td>\n",
       "      <td>0.948075</td>\n",
       "      <td>0.236263</td>\n",
       "      <td>0.112320</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.518293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>5120</td>\n",
       "      <td>400</td>\n",
       "      <td>0.947570</td>\n",
       "      <td>0.233796</td>\n",
       "      <td>0.112320</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.176842</td>\n",
       "      <td>0.512195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946699</td>\n",
       "      <td>0.243901</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.176842</td>\n",
       "      <td>0.512195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>600</td>\n",
       "      <td>0.946428</td>\n",
       "      <td>0.237743</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.508130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>500</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>0.236846</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.510163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>400</td>\n",
       "      <td>0.944724</td>\n",
       "      <td>0.235335</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.176842</td>\n",
       "      <td>0.512195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>3072</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.238654</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.177544</td>\n",
       "      <td>0.514228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>400</td>\n",
       "      <td>0.948792</td>\n",
       "      <td>0.236250</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.518293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>4096</td>\n",
       "      <td>500</td>\n",
       "      <td>0.948619</td>\n",
       "      <td>0.237786</td>\n",
       "      <td>0.110916</td>\n",
       "      <td>0.642276</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.510163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>3072</td>\n",
       "      <td>600</td>\n",
       "      <td>0.944718</td>\n",
       "      <td>0.234618</td>\n",
       "      <td>0.110916</td>\n",
       "      <td>0.642276</td>\n",
       "      <td>0.178246</td>\n",
       "      <td>0.516260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap  max_samples  n_estimators       ROC    pr_auc    p_at_1  \\\n",
       "0       False         5120           600  0.945589  0.241527  0.114426   \n",
       "1        True         4096           500  0.948059  0.240779  0.114075   \n",
       "2        True         4096           600  0.947024  0.238009  0.114075   \n",
       "3        True         4096           400  0.947488  0.234578  0.114075   \n",
       "4        True         5120           600  0.946432  0.233266  0.114075   \n",
       "5       False         5120           500  0.945856  0.244157  0.113373   \n",
       "6       False         5120           400  0.945553  0.242472  0.113022   \n",
       "7        True         5120           500  0.947182  0.235974  0.112671   \n",
       "8       False         4096           600  0.948075  0.236263  0.112320   \n",
       "9        True         5120           400  0.947570  0.233796  0.112320   \n",
       "10       True         3072           500  0.946699  0.243901  0.111969   \n",
       "11       True         3072           600  0.946428  0.237743  0.111969   \n",
       "12      False         3072           500  0.944501  0.236846  0.111969   \n",
       "13      False         3072           400  0.944724  0.235335  0.111969   \n",
       "14       True         3072           400  0.945980  0.238654  0.111267   \n",
       "15      False         4096           400  0.948792  0.236250  0.111267   \n",
       "16      False         4096           500  0.948619  0.237786  0.110916   \n",
       "17      False         3072           600  0.944718  0.234618  0.110916   \n",
       "\n",
       "      r_at_1   p_at_05   r_at_05  \n",
       "0   0.662602  0.180351  0.522358  \n",
       "1   0.660569  0.181053  0.524390  \n",
       "2   0.660569  0.178947  0.518293  \n",
       "3   0.660569  0.178947  0.518293  \n",
       "4   0.660569  0.177544  0.514228  \n",
       "5   0.656504  0.178947  0.518293  \n",
       "6   0.654472  0.180351  0.522358  \n",
       "7   0.652439  0.178246  0.516260  \n",
       "8   0.650407  0.178947  0.518293  \n",
       "9   0.650407  0.176842  0.512195  \n",
       "10  0.648374  0.176842  0.512195  \n",
       "11  0.648374  0.175439  0.508130  \n",
       "12  0.648374  0.176140  0.510163  \n",
       "13  0.648374  0.176842  0.512195  \n",
       "14  0.644309  0.177544  0.514228  \n",
       "15  0.644309  0.178947  0.518293  \n",
       "16  0.642276  0.176140  0.510163  \n",
       "17  0.642276  0.178246  0.516260  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected params: {'bootstrap': False, 'max_samples': 5120, 'n_estimators': 600}\n",
      "Selected r_at_1=0.6626, pr_auc=0.2415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.6626016260162602, 0.2415266316984472),\n",
       " {'bootstrap': False, 'max_samples': 5120, 'n_estimators': 600},\n",
       " IsolationForest(max_features=1, max_samples=5120, n_estimators=600, n_jobs=-1,\n",
       "                 random_state=42),\n",
       " array([0.4321302 , 0.42192052, 0.46422931, ..., 0.43185201, 0.41885989,\n",
       "        0.42263483]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_IF(param_grid, PRIMARY, SECONDARY, X_test=df_unlabelled, y_test=labels):\n",
    "\n",
    "    return tune_IF(param_grid, PRIMARY, SECONDARY, X_test, y_test)\n",
    "\n",
    "PRIMARY = \"r_at_1\"\n",
    "SECONDARY = \"pr_auc\"\n",
    "\n",
    "# Note that I have already narrowed down the param_grid through multiple iterations\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [400, 500, 600],\n",
    "    \"max_samples\": [3072, 4096, 5120],\n",
    "    \"bootstrap\": [False, True],\n",
    "    # Note: intentionally not tuning 'contamination' here\n",
    "}\n",
    "\n",
    "validate_IF(param_grid, PRIMARY, SECONDARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebff4fc",
   "metadata": {},
   "source": [
    "Our tuned Isolation Forest achieved ROC AUC = 0.95 and PR AUC = 0.24.\n",
    "\n",
    "At a 1% review budget, this corresponds to 11% precision and 66% recall, a 66× improvement over random guessing.\n",
    "In practice, this means fraud investigators could catch ~320 frauds (two-thirds of all fraud cases) while only reviewing 1% of total transactions.\n",
    "\n",
    "At a 0.5% review budget, this corresponds to 18% precision and 52% recall, a 104× improvement over random guessing.\n",
    "In practice, this means fraud investigators could catch ~255 frauds (just over half of all fraud cases) while only reviewing 0.5% of total transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30575e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: It is probably worth looking at why there is such a drop off in recall at 1% on the test set vs the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779468a",
   "metadata": {},
   "source": [
    "## Reducing Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881b2ea",
   "metadata": {},
   "source": [
    "In practice, it is feasible that increased PR AUC is not deemed to be worth the extra computational cost that comes with it, as only the top x% of transactions flagged as 'most suspicious' will be manually reviewed.  \n",
    "In this case, can we simplify the model so that it runs more efficiently, whilst maintaining good p_at_1 and r_at_1 scores?  \n",
    "Note that this assumes that the top 1% of transactions will be reviewed. Of course, if the percentage differs from 1% that would affect the necessary complexity of the model to retain performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "149a35f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_05</th>\n",
       "      <th>r_at_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>500</td>\n",
       "      <td>0.949611</td>\n",
       "      <td>0.246927</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>500</td>\n",
       "      <td>0.949668</td>\n",
       "      <td>0.244432</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.951602</td>\n",
       "      <td>0.253932</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.952530</td>\n",
       "      <td>0.252770</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.951178</td>\n",
       "      <td>0.251818</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.950611</td>\n",
       "      <td>0.251184</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.185965</td>\n",
       "      <td>0.540816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.950076</td>\n",
       "      <td>0.249435</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.185965</td>\n",
       "      <td>0.540816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>300</td>\n",
       "      <td>0.949982</td>\n",
       "      <td>0.244781</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.510204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>400</td>\n",
       "      <td>0.949156</td>\n",
       "      <td>0.243233</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>300</td>\n",
       "      <td>0.949831</td>\n",
       "      <td>0.241306</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.510204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>400</td>\n",
       "      <td>0.949306</td>\n",
       "      <td>0.241010</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.951327</td>\n",
       "      <td>0.249759</td>\n",
       "      <td>0.119298</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.185965</td>\n",
       "      <td>0.540816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>500</td>\n",
       "      <td>0.949345</td>\n",
       "      <td>0.243766</td>\n",
       "      <td>0.117544</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>500</td>\n",
       "      <td>0.949775</td>\n",
       "      <td>0.243579</td>\n",
       "      <td>0.117544</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.520408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>400</td>\n",
       "      <td>0.948798</td>\n",
       "      <td>0.230465</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.510204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>300</td>\n",
       "      <td>0.947850</td>\n",
       "      <td>0.223374</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>400</td>\n",
       "      <td>0.949242</td>\n",
       "      <td>0.231080</td>\n",
       "      <td>0.112281</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.171930</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>300</td>\n",
       "      <td>0.948225</td>\n",
       "      <td>0.221372</td>\n",
       "      <td>0.112281</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap  max_samples  n_estimators       ROC    pr_auc    p_at_1  \\\n",
       "0        True         1024           500  0.949611  0.246927  0.122807   \n",
       "1       False         1024           500  0.949668  0.244432  0.122807   \n",
       "2       False         2048           500  0.951602  0.253932  0.121053   \n",
       "3       False         2048           300  0.952530  0.252770  0.121053   \n",
       "4        True         2048           500  0.951178  0.251818  0.121053   \n",
       "5       False         2048           400  0.950611  0.251184  0.121053   \n",
       "6        True         2048           400  0.950076  0.249435  0.121053   \n",
       "7        True         1024           300  0.949982  0.244781  0.121053   \n",
       "8        True         1024           400  0.949156  0.243233  0.121053   \n",
       "9       False         1024           300  0.949831  0.241306  0.121053   \n",
       "10      False         1024           400  0.949306  0.241010  0.121053   \n",
       "11       True         2048           300  0.951327  0.249759  0.119298   \n",
       "12      False          512           500  0.949345  0.243766  0.117544   \n",
       "13       True          512           500  0.949775  0.243579  0.117544   \n",
       "14      False          512           400  0.948798  0.230465  0.115789   \n",
       "15      False          512           300  0.947850  0.223374  0.114035   \n",
       "16       True          512           400  0.949242  0.231080  0.112281   \n",
       "17       True          512           300  0.948225  0.221372  0.112281   \n",
       "\n",
       "      r_at_1   p_at_05   r_at_05  \n",
       "0   0.714286  0.182456  0.530612  \n",
       "1   0.714286  0.182456  0.530612  \n",
       "2   0.704082  0.178947  0.520408  \n",
       "3   0.704082  0.182456  0.530612  \n",
       "4   0.704082  0.178947  0.520408  \n",
       "5   0.704082  0.185965  0.540816  \n",
       "6   0.704082  0.185965  0.540816  \n",
       "7   0.704082  0.175439  0.510204  \n",
       "8   0.704082  0.182456  0.530612  \n",
       "9   0.704082  0.175439  0.510204  \n",
       "10  0.704082  0.178947  0.520408  \n",
       "11  0.693878  0.185965  0.540816  \n",
       "12  0.683673  0.178947  0.520408  \n",
       "13  0.683673  0.178947  0.520408  \n",
       "14  0.673469  0.175439  0.510204  \n",
       "15  0.663265  0.161404  0.469388  \n",
       "16  0.653061  0.171930  0.500000  \n",
       "17  0.653061  0.161404  0.469388  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected params: {'bootstrap': True, 'max_samples': 1024, 'n_estimators': 500}\n",
      "Selected r_at_1=0.7143, pr_auc=0.2469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7142857142857143, 0.24692654033227998),\n",
       " {'bootstrap': True, 'max_samples': 1024, 'n_estimators': 500},\n",
       " IsolationForest(bootstrap=True, max_features=1, max_samples=1024,\n",
       "                 n_estimators=500, n_jobs=-1, random_state=42),\n",
       " array([0.44779068, 0.48127543, 0.51621728, ..., 0.43898377, 0.42581122,\n",
       "        0.4321898 ]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRIMARY = \"r_at_1\"\n",
    "SECONDARY = \"pr_auc\"\n",
    "\n",
    "# Note that I have already narrowed down the param_grid through multiple iterations\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 400, 500],\n",
    "    \"max_samples\": [512, 1024, 2048],\n",
    "    \"bootstrap\": [False, True],\n",
    "    # Note: intentionally not tuning 'contamination' here\n",
    "}\n",
    "\n",
    "tune_IF(param_grid, PRIMARY, SECONDARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ca36623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_05</th>\n",
       "      <th>r_at_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946086</td>\n",
       "      <td>0.237263</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.174035</td>\n",
       "      <td>0.504065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946577</td>\n",
       "      <td>0.236902</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.648374</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.502033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.946597</td>\n",
       "      <td>0.236156</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>0.506098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>500</td>\n",
       "      <td>0.945790</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>0.506098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946113</td>\n",
       "      <td>0.230656</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.174035</td>\n",
       "      <td>0.504065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945729</td>\n",
       "      <td>0.227947</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>0.506098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>300</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.226303</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.487805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945665</td>\n",
       "      <td>0.233452</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.510163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.946227</td>\n",
       "      <td>0.231924</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.510163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945354</td>\n",
       "      <td>0.229338</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>0.506098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>300</td>\n",
       "      <td>0.945440</td>\n",
       "      <td>0.228341</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.169123</td>\n",
       "      <td>0.489837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.945949</td>\n",
       "      <td>0.235767</td>\n",
       "      <td>0.110214</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>0.506098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.217902</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.163509</td>\n",
       "      <td>0.473577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>500</td>\n",
       "      <td>0.946557</td>\n",
       "      <td>0.217760</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.164912</td>\n",
       "      <td>0.477642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945243</td>\n",
       "      <td>0.206630</td>\n",
       "      <td>0.107055</td>\n",
       "      <td>0.619919</td>\n",
       "      <td>0.162105</td>\n",
       "      <td>0.469512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>400</td>\n",
       "      <td>0.945584</td>\n",
       "      <td>0.206263</td>\n",
       "      <td>0.106704</td>\n",
       "      <td>0.617886</td>\n",
       "      <td>0.160702</td>\n",
       "      <td>0.465447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>300</td>\n",
       "      <td>0.945588</td>\n",
       "      <td>0.199190</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.447154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>300</td>\n",
       "      <td>0.945319</td>\n",
       "      <td>0.199443</td>\n",
       "      <td>0.104949</td>\n",
       "      <td>0.607724</td>\n",
       "      <td>0.155088</td>\n",
       "      <td>0.449187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap  max_samples  n_estimators       ROC    pr_auc    p_at_1  \\\n",
       "0        True         2048           500  0.946086  0.237263  0.111969   \n",
       "1       False         2048           500  0.946577  0.236902  0.111969   \n",
       "2       False         2048           300  0.946597  0.236156  0.111618   \n",
       "3        True         1024           500  0.945790  0.231643  0.111618   \n",
       "4       False         1024           500  0.946113  0.230656  0.111618   \n",
       "5       False         1024           400  0.945729  0.227947  0.111618   \n",
       "6       False         1024           300  0.945625  0.226303  0.111618   \n",
       "7        True         2048           400  0.945665  0.233452  0.111267   \n",
       "8       False         2048           400  0.946227  0.231924  0.111267   \n",
       "9        True         1024           400  0.945354  0.229338  0.111267   \n",
       "10       True         1024           300  0.945440  0.228341  0.111267   \n",
       "11       True         2048           300  0.945949  0.235767  0.110214   \n",
       "12       True          512           500  0.946875  0.217902  0.109512   \n",
       "13      False          512           500  0.946557  0.217760  0.109512   \n",
       "14      False          512           400  0.945243  0.206630  0.107055   \n",
       "15       True          512           400  0.945584  0.206263  0.106704   \n",
       "16       True          512           300  0.945588  0.199190  0.105300   \n",
       "17      False          512           300  0.945319  0.199443  0.104949   \n",
       "\n",
       "      r_at_1   p_at_05   r_at_05  \n",
       "0   0.648374  0.174035  0.504065  \n",
       "1   0.648374  0.173333  0.502033  \n",
       "2   0.646341  0.174737  0.506098  \n",
       "3   0.646341  0.174737  0.506098  \n",
       "4   0.646341  0.174035  0.504065  \n",
       "5   0.646341  0.174737  0.506098  \n",
       "6   0.646341  0.168421  0.487805  \n",
       "7   0.644309  0.176140  0.510163  \n",
       "8   0.644309  0.176140  0.510163  \n",
       "9   0.644309  0.174737  0.506098  \n",
       "10  0.644309  0.169123  0.489837  \n",
       "11  0.638211  0.174737  0.506098  \n",
       "12  0.634146  0.163509  0.473577  \n",
       "13  0.634146  0.164912  0.477642  \n",
       "14  0.619919  0.162105  0.469512  \n",
       "15  0.617886  0.160702  0.465447  \n",
       "16  0.609756  0.154386  0.447154  \n",
       "17  0.607724  0.155088  0.449187  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected params: {'bootstrap': True, 'max_samples': 2048, 'n_estimators': 500}\n",
      "Selected r_at_1=0.6484, pr_auc=0.2373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.6483739837398373, 0.23726276401612179),\n",
       " {'bootstrap': True, 'max_samples': 2048, 'n_estimators': 500},\n",
       " IsolationForest(bootstrap=True, max_features=1, max_samples=2048,\n",
       "                 n_estimators=500, n_jobs=-1, random_state=42),\n",
       " array([0.43000212, 0.42769133, 0.47371162, ..., 0.43189477, 0.42377308,\n",
       "        0.42540123]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_IF(param_grid, PRIMARY, SECONDARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2db4c",
   "metadata": {},
   "source": [
    "We can see that reducing the model complexity, we are still able to retain strong p_at_1 and r_at_1 values whilst reducing model complexity.\n",
    "\n",
    "From the above, we can reduce as far as n_neighbors = 300, max_samples = 1024 before we start seeing meaningful drop offs in performance on the top 1% of suspicious transactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
